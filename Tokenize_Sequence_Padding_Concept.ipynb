{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD44eZhYdZt3"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetFeatureExample = [\n",
        "                         'I love NLP',\n",
        "                         'I love NLU',\n",
        "                         'Do you love NLP?',\n",
        "                         'NLU is amazing and awesome!'\n",
        "]"
      ],
      "metadata": {
        "id": "SKPP6Ua4eK7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OOV ---> Out Of Vocabulary\n",
        "# This helps the tokenizer object to identify and mark those words\n",
        "# which are not the part of the vocabulary\n",
        "tokenizer = Tokenizer(oov_token=\"<DontKnow>\")"
      ],
      "metadata": {
        "id": "ay4226speWmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(datasetFeatureExample)"
      ],
      "metadata": {
        "id": "_SCG5SDie4XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqf8WW4ZfZ-t",
        "outputId": "81d2a2f5-08d9-4175-8dd4-a210df376d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<NahiHai>': 1,\n",
              " 'amazing': 9,\n",
              " 'and': 10,\n",
              " 'awesome': 11,\n",
              " 'do': 6,\n",
              " 'i': 3,\n",
              " 'is': 8,\n",
              " 'love': 2,\n",
              " 'nlp': 4,\n",
              " 'nlu': 5,\n",
              " 'you': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.texts_to_sequences(datasetFeatureExample)\n",
        "sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmmaACLGffY1",
        "outputId": "8da22b41-a20b-47c0-ec03-bb1738786aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 2, 4], [3, 2, 5], [6, 7, 2, 4], [5, 8, 9, 10, 11]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paddingData = pad_sequences(sequence)\n",
        "paddingData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq6_vJElgy8T",
        "outputId": "ea3e477f-d6df-49c0-c864-69e14b5a3ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  3,  2,  4],\n",
              "       [ 0,  0,  3,  2,  5],\n",
              "       [ 0,  6,  7,  2,  4],\n",
              "       [ 5,  8,  9, 10, 11]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testData = ['Welcome to my NLP class', 'My name is Prashant Nair', 'I am your trainer']\n",
        "\n",
        "seq = tokenizer.texts_to_sequences(testData)"
      ],
      "metadata": {
        "id": "BM4i3UzrhuBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0FlYP4biXaz",
        "outputId": "c156eaae-e844-4873-d3c3-8d7a606ffd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1, 1, 4, 1], [1, 1, 8, 1, 1], [3, 1, 1, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['<DontKnow>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfa8psbQiYQS",
        "outputId": "749b2ede-eac9-47a9-9cc9-828d65612507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3VEhAniib_v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}